# Scenario 8 â€” Native C# ONNX Inference (No Python)

Run VibeVoice TTS **entirely in C#** using ONNX Runtime. Zero Python dependency at runtime.

## Architecture

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         C# Application (ONNX Runtime)           â”‚
                    â”‚                                                 â”‚
  "Hello world" â”€â”€â–ºâ”‚  Tokenizer â”€â”€â–º text_encoder.onnx                â”‚
                    â”‚                     â”‚                           â”‚
                    â”‚              hidden states                      â”‚
                    â”‚                     â”‚                           â”‚
                    â”‚  noise â”€â”€â–º diffusion_step.onnx (Ã—5 steps)      â”‚
                    â”‚                     â”‚                           â”‚
                    â”‚              clean latents                      â”‚
                    â”‚                     â”‚                           â”‚
                    â”‚            acoustic_decoder.onnx â”€â”€â–º WAV audio  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Prerequisites

- [.NET 8.0 SDK](https://dotnet.microsoft.com/download/dotnet/8.0) or later
- ONNX model files (see [Export Models](#export-models) below)

## Export Models (One-Time Setup)

The ONNX models must be exported from the PyTorch model first. This is a one-time step requiring Python.

```bash
# Set up Python environment for export
cd src/scenario-08-onnx-native/export
pip install -r requirements_export.txt

# Export model subcomponents to ONNX
python export_model.py --output ../models

# Export voice presets to .npy format
python export_voice_presets.py --output ../models/voices

# Validate export accuracy (optional)
python validate_export.py --models-dir ../models
```

## Run the C# App

```bash
cd src/scenario-08-onnx-native/csharp
dotnet run -- --text "Hello! This is VibeVoice running natively in C sharp." --voice Carter
```

### CLI Options

| Option | Default | Description |
|--------|---------|-------------|
| `--text` | *(required)* | Text to synthesize |
| `--voice` | `Carter` | Voice preset (Carter, Davis, Emma, Frank, Grace, Mike) |
| `--output` | `output.wav` | Output WAV file path |
| `--models-dir` | `../models` | Directory containing ONNX models |

## Project Structure

```
scenario-08-onnx-native/
â”œâ”€â”€ README.md                           # This file
â”œâ”€â”€ export/                             # Python export tools (one-time use)
â”‚   â”œâ”€â”€ export_model.py                 # Export PyTorch â†’ ONNX subcomponents
â”‚   â”œâ”€â”€ export_voice_presets.py         # Convert .pt voice presets â†’ .npy
â”‚   â”œâ”€â”€ validate_export.py             # Compare PyTorch vs ONNX accuracy
â”‚   â””â”€â”€ requirements_export.txt         # Python deps for export only
â”œâ”€â”€ models/                             # Exported ONNX models (gitignored)
â”‚   â””â”€â”€ README.md                       # How to generate model files
â”œâ”€â”€ csharp/                             # C# native inference app
â”‚   â”œâ”€â”€ VibeVoiceOnnx.csproj
â”‚   â”œâ”€â”€ Program.cs                      # CLI entry point
â”‚   â”œâ”€â”€ Pipeline/
â”‚   â”‚   â”œâ”€â”€ VibeVoiceOnnxPipeline.cs   # Main inference orchestrator
â”‚   â”‚   â”œâ”€â”€ VibeVoiceTokenizer.cs      # BPE text tokenization
â”‚   â”‚   â”œâ”€â”€ DiffusionScheduler.cs      # DDPM noise schedule
â”‚   â”‚   â””â”€â”€ VoicePresetManager.cs      # Voice preset loading
â”‚   â””â”€â”€ Utils/
â”‚       â”œâ”€â”€ AudioWriter.cs              # WAV file writer
â”‚       â””â”€â”€ TensorHelpers.cs            # Tensor math utilities
â””â”€â”€ docs/
    â””â”€â”€ architecture.md                 # Technical deep-dive
```

## How It Works

1. **Text Tokenization** â€” Input text is tokenized using the HuggingFace BPE vocabulary (ported to C#)
2. **Text Encoding** â€” Token IDs run through `text_encoder.onnx` (LLM backbone) producing hidden states
3. **Diffusion Loop** â€” Starting from random noise, `diffusion_step.onnx` is called 5 times to denoise latent audio representations, conditioned on the text encoding and voice preset
4. **Audio Decoding** â€” Clean latents pass through `acoustic_decoder.onnx` to produce 24kHz audio samples
5. **WAV Output** â€” Audio samples are written as a standard WAV file

## Key Differences from Other Scenarios

| Aspect | Previous Approach | ONNX Native (Current) |
|--------|--------------------------|--------------------------|
| Runtime dependency | Python + PyTorch | None (pure C#) |
| Model format | PyTorch weights | ONNX |
| Deployment size | ~4 GB (Python + model) | ~1 GB (ONNX models only) |
| Startup time | ~30s (Python + model load) | ~5s (ONNX session load) |
| Cross-platform | Limited by Python | Full .NET support |
| Mobile/MAUI ready | No | Yes |

## Limitations

- **Export step requires Python** â€” a one-time requirement to convert the model
- **Numerical precision** â€” small floating-point differences vs. PyTorch (~1e-4 tolerance)
- **Model size** â€” ~1 GB total for the ONNX models (can be reduced with INT8 quantization)
- **Tokenizer** â€” simplified BPE implementation; may need updates for edge-case text inputs

## GPU Acceleration

For GPU inference on Windows, use the DirectML execution provider:

```bash
dotnet add package Microsoft.ML.OnnxRuntime.DirectML
```

For NVIDIA GPUs:

```bash
dotnet add package Microsoft.ML.OnnxRuntime.Gpu
```

## Hugging Face

The exported ONNX models are published on Hugging Face for easy download:

**ğŸ¤— [elbruno/VibeVoice-Realtime-0.5B-ONNX](https://huggingface.co/elbruno/VibeVoice-Realtime-0.5B-ONNX)**

### Download from Hugging Face (Python)

```python
from huggingface_hub import snapshot_download

local_dir = snapshot_download(
    "elbruno/VibeVoice-Realtime-0.5B-ONNX",
    allow_patterns=["*.onnx", "*.json", "*.npy", "voices/**"],
)
print(f"Models downloaded to: {local_dir}")
```

### Download from Hugging Face (Git)

```bash
git lfs install
git clone https://huggingface.co/elbruno/VibeVoice-Realtime-0.5B-ONNX models
```

### Publish Updated Models

After exporting new ONNX models, upload them to Hugging Face:

```bash
cd src/scenario-08-onnx-native/huggingface
pip install huggingface_hub
huggingface-cli login
python upload_to_hf.py --repo elbruno/VibeVoice-Realtime-0.5B-ONNX --models-dir ../models
```
