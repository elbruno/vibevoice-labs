# üéôÔ∏è VibeVoiceTTS

[![NuGet](https://img.shields.io/nuget/v/ElBruno.VibeVoiceTTS.svg?style=flat-square&logo=nuget)](https://www.nuget.org/packages/ElBruno.VibeVoiceTTS)
[![NuGet Downloads](https://img.shields.io/nuget/dt/ElBruno.VibeVoiceTTS.svg?style=flat-square&logo=nuget)](https://www.nuget.org/packages/ElBruno.VibeVoiceTTS)
[![Build Status](https://github.com/elbruno/ElBruno.VibeVoiceTTS/actions/workflows/publish.yml/badge.svg)](https://github.com/elbruno/ElBruno.VibeVoiceTTS/actions/workflows/publish.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=flat-square)](LICENSE)
[![HuggingFace](https://img.shields.io/badge/ü§ó_HuggingFace-ONNX_Models-orange?style=flat-square)](https://huggingface.co/elbruno/VibeVoice-Realtime-0.5B-ONNX)
[![GitHub stars](https://img.shields.io/github/stars/elbruno/ElBruno.VibeVoiceTTS?style=social)](https://github.com/elbruno/ElBruno.VibeVoiceTTS)
[![Twitter Follow](https://img.shields.io/twitter/follow/elbruno?style=social)](https://twitter.com/elbruno)

A .NET library for text-to-speech synthesis using Microsoft's [VibeVoice-Realtime-0.5B](https://huggingface.co/microsoft/VibeVoice-Realtime-0.5B) ‚Äî native C# inference via ONNX Runtime, no Python required at runtime.

## Features

- üîä **Natural Text-to-Speech** ‚Äî High-quality speech synthesis powered by VibeVoice-Realtime-0.5B
- üì¶ **NuGet Package** ‚Äî [`ElBruno.VibeVoiceTTS`](https://www.nuget.org/packages/ElBruno.VibeVoiceTTS) ‚Äî install and start generating speech in minutes
- ü§ñ **Pure C# Inference** ‚Äî ONNX Runtime, zero Python dependency at runtime
- üöÄ **GPU Acceleration** ‚Äî DirectML (any Windows GPU) and CUDA (NVIDIA) support with automatic CPU fallback
- üì• **Auto-Download** ‚Äî Models automatically downloaded from ü§ó HuggingFace on first use
- üåç **6 Voice Presets** ‚Äî Carter, Davis, Emma, Frank, Grace, Mike (English voices with multilingual experimental support)
- üíâ **Dependency Injection** ‚Äî First-class `IServiceCollection` integration
- üñ•Ô∏è **Cross-Platform** ‚Äî Windows, Linux, macOS, MAUI-ready

## Installation

```bash
dotnet add package ElBruno.VibeVoiceTTS
```

## Quick Start

### 1) Generate speech and save to WAV

```csharp
using ElBruno.VibeVoiceTTS;

using var tts = new VibeVoiceSynthesizer();
await tts.EnsureModelAvailableAsync(); // auto-downloads ~1.5 GB on first run

float[] audio = await tts.GenerateAudioAsync("Hello! Welcome to VibeVoiceTTS.", "Carter");
tts.SaveWav("output.wav", audio);
```

### 2) Use voice presets

```csharp
// Use the enum (recommended)
float[] carter = await tts.GenerateAudioAsync("Hello from Carter!", VibeVoicePreset.Carter);
float[] emma = await tts.GenerateAudioAsync("Hello from Emma!", VibeVoicePreset.Emma);

// Or use a string name ‚Äî both short and internal names work
float[] audio = await tts.GenerateAudioAsync("Hello!", "Carter");
float[] audio2 = await tts.GenerateAudioAsync("Hello!", "en-Carter_man"); // also works
```

### 3) Discover available voices

```csharp
// Voices currently downloaded on disk
string[] available = tts.GetAvailableVoices();
// ‚Üí ["Carter", "Emma"]  (default download includes Carter and Emma)

// All supported voices (including those not yet downloaded)
string[] supported = tts.GetSupportedVoices();
// ‚Üí ["Carter", "Davis", "Emma", "Frank", "Grace", "Mike"]

// Detailed metadata for all supported voices
VoiceInfo[] details = tts.GetSupportedVoiceDetails();
foreach (var voice in details)
    Console.WriteLine($"{voice.Name} ({voice.Gender}, {voice.Language})");
```

> **üí° On-demand voice download:** Only Carter and Emma are downloaded by default with `EnsureModelAvailableAsync()`. Other voices (Davis, Frank, Grace, Mike) are **automatically downloaded on first use** when you call `GenerateAudioAsync()`. You can also pre-download a specific voice:
> ```csharp
> await tts.EnsureVoiceAvailableAsync("Davis", progress);
> ```

### 4) Track download progress

```csharp
var progress = new Progress<DownloadProgress>(p =>
{
    if (p.Stage == DownloadStage.Downloading)
        Console.Write($"\r‚¨áÔ∏è [{p.CurrentFile}] {p.PercentComplete:F0}%");
    else
        Console.WriteLine($"{p.Stage}: {p.Message}");
});

await tts.EnsureModelAvailableAsync(progress);
```

### 5) Configure options

```csharp
var options = new VibeVoiceOptions
{
    ModelPath = @"D:\models\vibevoice",  // Custom model location (default: OS cache)
    DiffusionSteps = 20,                 // Quality vs speed tradeoff
    CfgScale = 1.5f,                     // Classifier-free guidance scale
    SampleRate = 24000,                  // Output sample rate
};

using var tts = new VibeVoiceSynthesizer(options);
```

| Option | Default | Description |
|--------|---------|-------------|
| `ModelPath` | OS cache* | Directory where ONNX models are stored and downloaded |
| `HuggingFaceRepo` | `elbruno/VibeVoice-Realtime-0.5B-ONNX` | HuggingFace repo for model downloads |
| `DiffusionSteps` | `20` | Number of diffusion denoising steps |
| `CfgScale` | `1.5` | Classifier-free guidance scale |
| `SampleRate` | `24000` | Output audio sample rate (Hz) |
| `Seed` | `42` | Random seed for reproducible output |
| `ExecutionProvider` | `Cpu` | ONNX Runtime execution provider (`Cpu`, `DirectML`, `Cuda`) |
| `GpuDeviceId` | `0` | GPU device index (used with DirectML or CUDA) |

*\*Default model cache: Windows: `%LOCALAPPDATA%\ElBruno\VibeVoice\models` ¬∑ Linux/macOS: `~/.local/share/elbruno/vibevoice/models`*

### 6) GPU Acceleration

Enable GPU acceleration by setting the execution provider and installing the corresponding NuGet package:

```bash
# For DirectML (any Windows GPU ‚Äî NVIDIA, AMD, Intel):
dotnet add package Microsoft.ML.OnnxRuntime.DirectML

# For CUDA (NVIDIA only ‚Äî Windows and Linux):
dotnet add package Microsoft.ML.OnnxRuntime.Gpu
```

```csharp
// DirectML ‚Äî recommended for Windows desktop apps
var options = new VibeVoiceOptions
{
    ExecutionProvider = ExecutionProvider.DirectML,
    GpuDeviceId = 0   // optional, selects which GPU
};
using var tts = new VibeVoiceSynthesizer(options);

// CUDA ‚Äî for NVIDIA GPUs with CUDA drivers
var options = new VibeVoiceOptions
{
    ExecutionProvider = ExecutionProvider.Cuda,
    GpuDeviceId = 0
};
using var tts = new VibeVoiceSynthesizer(options);
```

> **üí° Note:** If the selected GPU provider is unavailable (missing NuGet package or no compatible GPU), the library automatically falls back to CPU inference. When using DirectML, models with dynamic tensor shapes (LM models, acoustic decoder) run on CPU while fixed-shape models (prediction head, connector, EOS classifier) use GPU ‚Äî this works around known DirectML limitations with dynamic Reshape and ConvTranspose operations.

### 7) Dependency Injection

```csharp
builder.Services.AddVibeVoice(options =>
{
    options.DiffusionSteps = 20;
});

// Then inject IVibeVoiceSynthesizer in your services
```

> **üí° Tip:** For best results, keep sentences short (~10 words). Longer text may produce artifacts due to model limitations. Consider splitting long text into sentences.

## üó£Ô∏è Voices & Languages

| Voice | Gender | Preset Enum | Internal Name |
|-------|--------|-------------|---------------|
| Carter | Male | `VibeVoicePreset.Carter` | `en-Carter_man` |
| Davis | Male | `VibeVoicePreset.Davis` | `en-Davis_man` |
| Emma | Female | `VibeVoicePreset.Emma` | `en-Emma_woman` |
| Frank | Male | `VibeVoicePreset.Frank` | `en-Frank_man` |
| Grace | Female | `VibeVoicePreset.Grace` | `en-Grace_woman` |
| Mike | Male | `VibeVoicePreset.Mike` | `en-Mike_man` |

All 6 voice presets are available on [HuggingFace](https://huggingface.co/elbruno/VibeVoice-Realtime-0.5B-ONNX/tree/main/voices) and are downloaded on-demand when first used.

> **‚ö° Migration note:** In versions prior to 0.2.0, `GetAvailableVoices()` returned all 6 voices regardless of download status. Starting with 0.2.0, it returns only voices **actually downloaded on disk**. Use `GetSupportedVoices()` to see all 6 known presets. Voices are auto-downloaded on first use with `GenerateAudioAsync()`, or pre-download with `EnsureVoiceAvailableAsync("Davis")`.

**Language support:** The model is primarily trained on **English**, with experimental multilingual capabilities (e.g., Spanish, French, German). Results may vary for non-English text.

üìñ For full details on the model, supported languages, and voice characteristics, see the official [VibeVoice documentation on HuggingFace](https://huggingface.co/microsoft/VibeVoice-Realtime-0.5B) and the [VibeVoice GitHub repository](https://github.com/microsoft/VibeVoice).

For the complete API reference and advanced usage, see the [Getting Started Guide](docs/GETTING_STARTED.md).

## Scenarios

This repository includes example projects demonstrating different ways to use VibeVoice:

| # | Status | Scenario | Stack | Level | Description |
|---|--------|----------|-------|-------|-------------|
| 1 | ‚úÖ | [Simple Python Script](src/scenario-01-simple/) | Python | Beginner | Minimal TTS demo ‚Äî useful for model export and testing |
| 2 | ‚úÖ | [Full-Stack App](src/scenario-02-fullstack/) | Python + Blazor + Aspire | Intermediate | Web app with FastAPI backend and Blazor frontend |
| 3 | ‚úÖ | [**C# Console App**](src/scenario-03-csharp-simple/) | **C# (.NET 8)** | **Beginner** | **Recommended starting point** ‚Äî pure C# with `ElBruno.VibeVoiceTTS` |
| 4 | ‚úÖ | [Full C# with Aspire](src/scenario-04-meai/) | C# + Blazor + Aspire | Intermediate | Full-stack C# app with WebAPI + Blazor frontend |
| 5 | ‚úÖ | [Batch Processing](src/scenario-05-batch-processing/) | Python | Intermediate | CLI to convert folders of .txt to .wav |
| 6 | ‚úÖ | [Real-Time Streaming](src/scenario-06-streaming-realtime/) | Python | Intermediate | Chunked audio playback for low-latency |
| 7 | üöß | [MAUI Mobile](src/scenario-07-maui-mobile/) | C# (.NET 10 MAUI) | Advanced | Cross-platform app ‚Äî **work in progress** (currently uses Python backend, migration to `ElBruno.VibeVoiceTTS` planned) |
| 8 | ‚úÖ | [ONNX Export](src/scenario-08-onnx-native/) | Python ‚Üí C# | Advanced | ONNX model export tools and pipeline docs |

> **Note:** Python scenarios (1, 2, 5, 6) are primarily for ONNX model export, testing, and reference. The C# scenarios (3, 4) run entirely in .NET with no Python dependency. See the [Scenarios Guide](docs/scenarios.md) for details.

## ONNX Models on HuggingFace

Pre-exported ONNX models are available on HuggingFace ‚Äî the C# library downloads them automatically:

**ü§ó [elbruno/VibeVoice-Realtime-0.5B-ONNX](https://huggingface.co/elbruno/VibeVoice-Realtime-0.5B-ONNX)**

The model includes 9 ONNX files (autoregressive pipeline with KV-cache) and 6 voice presets. See [Scenario 8](src/scenario-08-onnx-native/) for export details.

## Documentation

| Topic | Description |
|-------|-------------|
| [Getting Started](docs/GETTING_STARTED.md) | Prerequisites, setup, and first steps |
| [Scenarios Guide](docs/scenarios.md) | Detailed descriptions of all 8 scenarios |
| [Architecture](docs/ARCHITECTURE.md) | System design, ONNX pipeline, and data flow |
| [Project Structure](docs/project-structure.md) | Repository layout and file organization |
| [API Reference](docs/API_REFERENCE.md) | REST API documentation (for web scenarios) |
| [User Manual](docs/USER_MANUAL.md) | End-user guide for web interfaces |
| [Publishing](docs/publishing.md) | NuGet publishing with GitHub Actions |

## Tech Stack

| Layer | Technology | Purpose |
|-------|------------|---------|
| **C# TTS Library** | [ElBruno.VibeVoiceTTS](https://www.nuget.org/packages/ElBruno.VibeVoiceTTS) | Reusable .NET library with HuggingFace auto-download |
| **TTS Model** | [VibeVoice-Realtime-0.5B](https://huggingface.co/microsoft/VibeVoice-Realtime-0.5B) | Microsoft's text-to-speech model |
| **Inference** | [ONNX Runtime](https://onnxruntime.ai/) | Native C# model inference |
| **Frontend** | [Blazor](https://dotnet.microsoft.com/apps/aspnet/web-apps/blazor) (.NET 10) | Interactive web UI |
| **Orchestration** | [.NET Aspire](https://learn.microsoft.com/en-us/dotnet/aspire/) | Service discovery & health checks |

## Building from Source

```bash
git clone https://github.com/elbruno/ElBruno.VibeVoiceTTS.git
cd ElBruno.VibeVoiceTTS
dotnet build src/ElBruno.VibeVoiceTTS/ElBruno.VibeVoiceTTS.csproj
dotnet test src/ElBruno.VibeVoiceTTS.Tests/ElBruno.VibeVoiceTTS.Tests.csproj
```

### Requirements

- .NET 8.0 SDK or later
- ONNX Runtime compatible platform (Windows, Linux, macOS)
- Python 3.11+ (only needed for ONNX model export ‚Äî not for runtime use)

## üîó Related Projects

- <a href="https://github.com/elbruno/ElBruno.PersonaPlex">ElBruno.PersonaPlex</a> ‚Äî C# wrapper for NVIDIA's PersonaPlex-7B-v1 full-duplex speech-to-speech model, using ONNX Runtime for local inference. Pre-exported ONNX models: <a href="https://huggingface.co/elbruno/personaplex-7b-v1-onnx">elbruno/personaplex-7b-v1-onnx</a>

## ü§ù Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## üìÑ License

This project is licensed under the MIT License ‚Äî see the [LICENSE](LICENSE) file for details.

## üëã About the Author

Hi! I'm **ElBruno** üß°, a passionate developer and content creator exploring AI, .NET, and modern development practices.

**Made with ‚ù§Ô∏è by [ElBruno](https://github.com/elbruno)**

If you like this project, consider following my work across platforms:

- üìª **Podcast**: [No Tienen Nombre](https://notienenombre.com) ‚Äî Spanish-language episodes on AI, development, and tech culture
- üíª **Blog**: [ElBruno.com](https://elbruno.com) ‚Äî Deep dives on embeddings, RAG, .NET, and local AI
- üì∫ **YouTube**: [youtube.com/elbruno](https://www.youtube.com/elbruno) ‚Äî Demos, tutorials, and live coding
- üîó **LinkedIn**: [@elbruno](https://www.linkedin.com/in/elbruno/) ‚Äî Professional updates and insights
- ùïè **Twitter**: [@elbruno](https://www.x.com/in/elbruno/) ‚Äî Quick tips, releases, and tech news